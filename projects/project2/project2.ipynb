{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de047a38-145e-4c9c-b358-97472554bcc4",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b21e607-fcbb-480b-9abe-3f9536cb0b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: delta-spark in /opt/conda/lib/python3.11/site-packages (3.3.0)\n",
      "Requirement already satisfied: pyspark<3.6.0,>=3.5.3 in /usr/local/spark/python (from delta-spark) (3.5.3)\n",
      "Requirement already satisfied: importlib-metadata>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from delta-spark) (8.5.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=1.0.0->delta-spark) (3.20.2)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.11/site-packages (from pyspark<3.6.0,>=3.5.3->delta-spark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install delta-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7cadb3c-ae8f-4cf8-9b74-477eea83109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "builder = SparkSession.builder.appName(\"project2\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a9f55-9d79-4a43-a3eb-2a746e9bc4f6",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e203a57-848a-4c19-9e64-74f1fc02d118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- trip_time_in_secs: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- pickup_longitude: string (nullable = true)\n",
      " |-- pickup_latitude: string (nullable = true)\n",
      " |-- dropoff_longitude: string (nullable = true)\n",
      " |-- dropoff_latitude: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- surcharge: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the expected column names based on the CSV's field count\n",
    "columns = [\n",
    "    \"medallion\", \"hack_license\", \"pickup_datetime\", \"dropoff_datetime\",\n",
    "    \"trip_time_in_secs\", \"trip_distance\", \"pickup_longitude\", \"pickup_latitude\",\n",
    "    \"dropoff_longitude\", \"dropoff_latitude\", \"payment_type\", \"fare_amount\",\n",
    "    \"surcharge\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"total_amount\"\n",
    "]\n",
    "\n",
    "df = spark.read.option(\"header\", \"false\").csv(\"input/sorted_data.csv\")\n",
    "df = df.toDF(*columns)\n",
    "df.printSchema()\n",
    "\n",
    "fraction = 1.0 / 12  # Approximately 0.03\n",
    "df_sample = df.sample(withReplacement=False, fraction=fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee564ad2-117b-4678-9fc6-79c2b16b8c79",
   "metadata": {},
   "source": [
    "## Data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a46348fb-cb0f-46c2-8367-d40e5b355a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+-------------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "|           medallion|        hack_license|    pickup_datetime|   dropoff_datetime|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|\n",
      "+--------------------+--------------------+-------------------+-------------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "|1390FB380189DF6BB...|BE317B986700F63C4...|2013-01-01 00:01:00|2013-01-01 00:03:00|              120|         0.48|      -74.004173|      40.720947|       -74.003838|       40.726189|         CSH|        4.0|      0.5|    0.5|       0.0|         0.0|        5.00|\n",
      "|E07A1976036B82DA9...|F33756EA65252C595...|2013-01-01 00:01:00|2013-01-01 00:03:00|              120|         0.01|      -73.982216|      40.768768|       -73.982132|       40.768639|         CSH|        3.0|      0.5|    0.5|       0.0|         0.0|        4.00|\n",
      "|423AF240E03E7D433...|A01296230B401AEEB...|2013-01-01 00:00:10|2013-01-01 00:03:43|              212|          0.8|      -73.979179|      40.740398|       -73.988052|       40.732304|         CRD|        5.0|      0.5|    0.5|       1.5|         0.0|        7.50|\n",
      "|87EC61B520189EFEA...|2B9F6F2C53DF205A4...|2013-01-01 00:02:00|2013-01-01 00:04:00|              120|         0.72|      -73.977089|      40.789925|       -73.984505|       40.782444|         CSH|        4.5|      0.5|    0.5|       0.0|         0.0|        5.50|\n",
      "|182AEEFB53A1EC846...|968B835043E20F11E...|2013-01-01 00:01:26|2013-01-01 00:04:40|              193|          0.6|      -73.965012|      40.755863|       -73.973694|       40.755215|         CRD|        4.5|      0.5|    0.5|       1.1|         0.0|        6.60|\n",
      "|54A0206BB6609ED15...|F9CBA770163025BD2...|2013-01-01 00:01:05|2013-01-01 00:04:59|              234|          0.7|      -73.978111|      40.788967|       -73.976410|       40.780838|         CRD|        5.0|      0.5|    0.5|       1.0|         0.0|        7.00|\n",
      "|120E700FE35B2DDBE...|3EDDD1433E2276DF9...|2013-01-01 00:03:00|2013-01-01 00:05:00|              120|         0.52|      -73.981972|      40.752525|       -73.985313|       40.747738|         CSH|        4.0|      0.5|    0.5|       0.0|         0.0|        5.00|\n",
      "|2627FB9C3C1C9EC33...|A7EE9AEDB7325F55F...|2013-01-01 00:03:00|2013-01-01 00:05:00|              120|         0.52|      -73.961349|      40.716503|       -73.956383|       40.721107|         CSH|        3.5|      0.5|    0.5|       0.0|         0.0|        4.50|\n",
      "|6C125C5EA35888CA6...|C42312F4A144704A4...|2013-01-01 00:01:47|2013-01-01 00:05:03|              195|          1.1|      -73.979111|      40.743656|       -73.985306|       40.732075|         CSH|        5.5|      0.5|    0.5|       0.0|         0.0|        6.50|\n",
      "|6C8EA4103E23404EA...|390D55D0BCD554802...|2013-01-01 00:03:00|2013-01-01 00:06:00|              180|         0.58|      -73.979561|      40.776470|       -73.982765|       40.771801|         CSH|        4.0|      0.5|    0.5|       0.0|         0.0|        5.00|\n",
      "|7CC2C787A937EE1F8...|0758FB6257076E88C...|2013-01-01 00:00:00|2013-01-01 00:06:00|              360|         0.98|      -73.978325|      40.778091|       -73.981834|       40.768639|         CSH|        6.0|      0.5|    0.5|       0.0|         0.0|        7.00|\n",
      "|D41D773421934B51B...|9E7F4E2AF38E8542F...|2013-01-01 00:03:00|2013-01-01 00:06:00|              180|         0.59|      -73.993675|      40.727268|       -73.991653|       40.734322|         CSH|        4.5|      0.5|    0.5|       0.0|         0.0|        5.50|\n",
      "|EA00A64CBDB68C77D...|89A9E9D2677AB047F...|2013-01-01 00:05:16|2013-01-01 00:06:58|              102|          0.4|      -73.977501|      40.746433|       -73.974136|       40.751320|         CSH|        3.5|      0.5|    0.5|       0.0|         0.0|        4.50|\n",
      "|59C232188382C25A5...|52C57B70022A7B6CF...|2013-01-01 00:03:00|2013-01-01 00:07:00|              240|         0.67|      -73.980782|      40.729763|       -73.979607|       40.737469|         CSH|        4.5|      0.5|    0.5|       0.0|         0.0|        5.50|\n",
      "|67ECEA008EF4B5C5C...|F5FBCCEA1D840B81E...|2013-01-01 00:02:00|2013-01-01 00:07:00|              300|         1.32|      -73.968964|      40.758125|       -73.953972|       40.766975|         CRD|        6.5|      0.5|    0.5|       1.4|         0.0|        8.90|\n",
      "|7166914A326D84915...|FE44D0EA86E9882E9...|2013-01-01 00:02:00|2013-01-01 00:07:00|              300|         0.91|      -73.992805|      40.734070|       -73.981659|       40.736805|         CRD|        5.5|      0.5|    0.5|       1.2|         0.0|        7.70|\n",
      "|96BDDFD03647F713A...|4BE87B7C3B354AB84...|2013-01-01 00:03:00|2013-01-01 00:07:00|              240|         1.33|      -73.994331|      40.756058|       -74.007172|       40.741413|         CRD|        6.0|      0.5|    0.5|      1.95|         0.0|        8.95|\n",
      "|D97FE07A39B43CD68...|45FEFCC80DC40C817...|2013-01-01 00:01:09|2013-01-01 00:07:02|              352|          1.1|      -73.977684|      40.786991|       -73.980812|       40.771576|         CRD|        6.5|      0.5|    0.5|       1.0|         0.0|        8.50|\n",
      "|A38882246FC643994...|6DA75027BA51A8447...|2013-01-01 00:01:34|2013-01-01 00:07:21|              347|          1.1|      -73.962639|      40.794666|       -73.952980|       40.808300|         CSH|        6.5|      0.5|    0.5|       0.0|         0.0|        7.50|\n",
      "|0B57B9633A2FECD3D...|DC47AE0CDBCEC1B97...|2013-01-01 00:02:39|2013-01-01 00:07:51|              311|          1.1|      -73.948708|      40.711220|       -73.966774|       40.710503|         CSH|        6.0|      0.5|    0.5|       0.0|         0.0|        7.00|\n",
      "+--------------------+--------------------+-------------------+-------------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp\n",
    "\n",
    "# Convert pickup and dropoff datetimes to timestamps\n",
    "df_sample = df_sample.withColumn(\"pickup_datetime\", to_timestamp(col(\"pickup_datetime\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "                     .withColumn(\"dropoff_datetime\", to_timestamp(col(\"dropoff_datetime\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "clean_df = df_sample.filter(\n",
    "    (col(\"pickup_datetime\").isNotNull()) &\n",
    "    (col(\"dropoff_datetime\").isNotNull()) &\n",
    "    (col(\"medallion\").isNotNull()) & (col(\"medallion\") != \"\") &\n",
    "    (col(\"hack_license\").isNotNull()) & (col(\"hack_license\") != \"\") &\n",
    "    (col(\"trip_distance\").cast(\"float\") > 0) &\n",
    "    (col(\"fare_amount\").cast(\"float\") > 0)\n",
    ")\n",
    "\n",
    "clean_df = clean_df.withColumn(\"trip_time_in_secs\", col(\"trip_time_in_secs\").cast(\"int\")) \\\n",
    "                   .withColumn(\"trip_distance\", col(\"trip_distance\").cast(\"float\")) \\\n",
    "                   .withColumn(\"fare_amount\", col(\"fare_amount\").cast(\"float\")) \\\n",
    "                   .withColumn(\"surcharge\", col(\"surcharge\").cast(\"float\")) \\\n",
    "                   .withColumn(\"mta_tax\", col(\"mta_tax\").cast(\"float\")) \\\n",
    "                   .withColumn(\"tip_amount\", col(\"tip_amount\").cast(\"float\")) \\\n",
    "                   .withColumn(\"tolls_amount\", col(\"tolls_amount\").cast(\"float\"))\n",
    "clean_df.count()\n",
    "clean_df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54a3e5f-f084-43bb-8956-6f7f33b97772",
   "metadata": {},
   "source": [
    "## Query 1 - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11319598-cc2a-48ea-99e1-865c041e8aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max dropoff datetime: 2014-01-01 00:37:00\n",
      "+----------+----------+---------------+\n",
      "|start_cell|end_cell  |Number_of_Rides|\n",
      "+----------+----------+---------------+\n",
      "|4073_-7399|4075_-7400|2              |\n",
      "|4076_-7399|4075_-7400|2              |\n",
      "|4076_-7399|4072_-7399|2              |\n",
      "|4071_-7401|4069_-7386|1              |\n",
      "|4075_-7397|4079_-7398|1              |\n",
      "|4067_-7396|4072_-7395|1              |\n",
      "|4081_-7392|4083_-7385|1              |\n",
      "|4076_-7398|4075_-7400|1              |\n",
      "|4064_-7378|4061_-7392|1              |\n",
      "|4069_-7394|4074_-7387|1              |\n",
      "+----------+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, floor, concat, lit, current_timestamp, expr\n",
    "from datetime import timedelta\n",
    "\n",
    "max_dropoff = clean_df.agg({\"dropoff_datetime\": \"max\"}).collect()[0][0]\n",
    "print(\"Max dropoff datetime:\", max_dropoff)\n",
    "\n",
    "ref_time = max_dropoff - timedelta(minutes=30)\n",
    "\n",
    "# Create grid cell identifiers for pickup (start_cell) and drop-off (end_cell)\n",
    "cell_size = 0.01\n",
    "\n",
    "df_routes = clean_df.withColumn(\n",
    "    \"start_cell\",\n",
    "    concat(\n",
    "        floor(col(\"pickup_latitude\") / cell_size),\n",
    "        lit(\"_\"),\n",
    "        floor(col(\"pickup_longitude\") / cell_size)\n",
    "    )\n",
    ").withColumn(\n",
    "    \"end_cell\",\n",
    "    concat(\n",
    "        floor(col(\"dropoff_latitude\") / cell_size),\n",
    "        lit(\"_\"),\n",
    "        floor(col(\"dropoff_longitude\") / cell_size)\n",
    "    )\n",
    ")\n",
    "\n",
    "df_last30 = df_routes.filter(col(\"dropoff_datetime\") >= lit(ref_time))\n",
    "\n",
    "\n",
    "# Group by start and end cell and count the rides\n",
    "df_frequent_routes = df_last30.groupBy(\"start_cell\", \"end_cell\").count() \\\n",
    "    .withColumnRenamed(\"count\", \"Number_of_Rides\")\n",
    "\n",
    "top10_routes = df_frequent_routes.orderBy(col(\"Number_of_Rides\").desc()).limit(10)\n",
    "top10_routes.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aa4abb-f52a-40b4-b71e-c37c552a757f",
   "metadata": {},
   "source": [
    "## Query 1 - Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16784a00-324c-4192-bc63-3ee8bf0a1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the cleansed data to a Delta table in a writable directory.\n",
    "clean_df.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta/taxi_data\")\n",
    "streaming_df = spark.readStream.format(\"delta\").load(\"/tmp/delta/taxi_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fe1282a-f816-4eba-b092-a17b31f5bd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- trip_time_in_secs: integer (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- pickup_longitude: string (nullable = true)\n",
      " |-- pickup_latitude: string (nullable = true)\n",
      " |-- dropoff_longitude: string (nullable = true)\n",
      " |-- dropoff_latitude: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: float (nullable = true)\n",
      " |-- surcharge: float (nullable = true)\n",
      " |-- mta_tax: float (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      "\n",
      "+--------------------------------+--------------------------------+-------------------+-------------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "|medallion                       |hack_license                    |pickup_datetime    |dropoff_datetime   |trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|\n",
      "+--------------------------------+--------------------------------+-------------------+-------------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "|8F765363C77E091F4F364858A370AE9C|202CC839A8CCC598FB7BE5FB52159E43|2013-02-02 00:48:00|2013-02-02 01:00:00|720              |2.84         |-74.001350      |40.735992      |-73.971779       |40.758003       |CSH         |11.5       |0.5      |0.5    |0.0       |0.0         |12.50       |\n",
      "|901BAD071B1C693D943B2BAA3FE6E623|4FBF0FE605244EBB55F7139279A1D6BE|2013-02-02 00:57:00|2013-02-02 01:00:00|180              |0.85         |-73.984024      |40.746418      |-73.974541       |40.750763       |CSH         |4.5        |0.5      |0.5    |0.0       |0.0         |5.50        |\n",
      "|A506888A914B08DDA4C1FD8649BA3C28|7961BA824986F5B968565C4D894A5074|2013-02-02 00:56:00|2013-02-02 01:00:00|240              |0.38         |-73.993965      |40.717880      |-73.993965       |40.717880       |CRD         |4.5        |0.5      |0.5    |1.25      |0.0         |6.75        |\n",
      "|B458C7D184125F689833D71A5A648B76|FC1A705DA838C6B82B123D37B91C365E|2013-02-02 00:57:00|2013-02-02 01:00:00|180              |1.35         |-73.953560      |40.775311      |-73.941643       |40.787575       |CSH         |5.5        |0.5      |0.5    |0.0       |0.0         |6.50        |\n",
      "|BE386D8524FCD16B3727DCF0A32D9B25|4EB96EC9F3A42794DEE233EC8A2616CE|2013-02-02 00:45:00|2013-02-02 01:00:00|900              |2.8          |-73.985504      |40.731709      |-73.987419       |40.760769       |CRD         |12.5       |0.5      |0.5    |2.6       |0.0         |16.10       |\n",
      "+--------------------------------+--------------------------------+-------------------+-------------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Row count: 14334468\n"
     ]
    }
   ],
   "source": [
    "# 1) Read the Delta table in batch mode\n",
    "check_df = spark.read.format(\"delta\").load(\"/tmp/delta/taxi_data\")\n",
    "\n",
    "# 2) See the schema\n",
    "check_df.printSchema()\n",
    "\n",
    "# 3) Inspect some rows\n",
    "check_df.show(5, truncate=False)\n",
    "\n",
    "# 4) Count the rows\n",
    "print(\"Row count:\", check_df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05031d45-276b-4917-a94d-1205c449b158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window filter: dropoff_datetime >= 2014-01-01 00:32:18\n",
      "df_last30 count = 3\n",
      "+--------------------+--------------------+-------------------+-------------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+--------------------+----------------+-----------------+----------+-----------------+------------------+--------+\n",
      "|           medallion|        hack_license|    pickup_datetime|   dropoff_datetime|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|         ingest_time|pickup_cell_east|pickup_cell_south|start_cell|dropoff_cell_east|dropoff_cell_south|end_cell|\n",
      "+--------------------+--------------------+-------------------+-------------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+--------------------+----------------+-----------------+----------+-----------------+------------------+--------+\n",
      "|FE6C2621EAF58A69A...|97191A64A3C40CFD2...|2013-12-31 23:34:00|2014-01-01 00:42:00|             4080|         7.01|      -73.997566|      40.763096|       -73.926826|       40.743900|         CSH|       44.0|      0.5|    0.5|       0.0|         0.0|       45.00|2025-03-19 22:24:...|             153|              159|   153.159|              165|               163| 165.163|\n",
      "|B42FC03D269AA4FBA...|106116F0B19797E41...|2013-12-31 23:57:36|2014-01-01 00:51:19|             3222|          7.9|      -74.004570|      40.721470|       -73.959282|       40.811058|         CRD|       36.0|      0.5|    0.5|      9.25|         0.0|       46.25|2025-03-19 22:24:...|             152|              168|   152.168|              160|               148| 160.148|\n",
      "|F7E6BF13B6A8E8FD0...|6AC6033E0F915C291...|2013-12-31 22:45:43|2014-01-01 01:02:18|             8195|         12.5|      -73.974464|      40.761929|       -73.988609|       40.693043|         CSH|       88.5|      0.5|    0.5|       0.0|         0.0|       89.50|2025-03-19 22:24:...|             157|              159|   157.159|              155|               174| 155.174|\n",
      "+--------------------+--------------------+-------------------+-------------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+--------------------+----------------+-----------------+----------+-----------------+------------------+--------+\n",
      "\n",
      "Update for batch 0 : {'pickup_datetime': datetime.datetime(2013, 12, 31, 22, 45, 43), 'dropoff_datetime': datetime.datetime(2014, 1, 1, 1, 2, 18), 'delay': 31.757094, 'start_cell_id_1': '157.159', 'end_cell_id_1': '155.174', 'start_cell_id_2': '152.168', 'end_cell_id_2': '160.148', 'start_cell_id_3': '153.159', 'end_cell_id_3': '165.163', 'start_cell_id_4': None, 'end_cell_id_4': None, 'start_cell_id_5': None, 'end_cell_id_5': None, 'start_cell_id_6': None, 'end_cell_id_6': None, 'start_cell_id_7': None, 'end_cell_id_7': None, 'start_cell_id_8': None, 'end_cell_id_8': None, 'start_cell_id_9': None, 'end_cell_id_9': None, 'start_cell_id_10': None, 'end_cell_id_10': None}\n",
      "+-------------------+-------------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+----------------+--------------+---------+\n",
      "|pickup_datetime    |dropoff_datetime   |start_cell_id_1|end_cell_id_1|start_cell_id_2|end_cell_id_2|start_cell_id_3|end_cell_id_3|start_cell_id_4|end_cell_id_4|start_cell_id_5|end_cell_id_5|start_cell_id_6|end_cell_id_6|start_cell_id_7|end_cell_id_7|start_cell_id_8|end_cell_id_8|start_cell_id_9|end_cell_id_9|start_cell_id_10|end_cell_id_10|delay    |\n",
      "+-------------------+-------------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+----------------+--------------+---------+\n",
      "|2013-12-31 22:45:43|2014-01-01 01:02:18|157.159        |155.174      |152.168        |160.148      |153.159        |165.163      |NULL           |NULL         |NULL           |NULL         |NULL           |NULL         |NULL           |NULL         |NULL           |NULL         |NULL           |NULL         |NULL            |NULL          |31.757094|\n",
      "+-------------------+-------------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+---------------+-------------+----------------+--------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, floor, concat, lit, current_timestamp, to_timestamp, expr\n",
    ")\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import timedelta, datetime\n",
    "from pyspark.sql.types import StructType, StructField, TimestampType, DoubleType, StringType\n",
    "\n",
    "# Define your grid constants for the 500m x 500m grid\n",
    "grid_origin_lat = 41.474937\n",
    "grid_origin_lon = -74.913585\n",
    "delta_lat = 0.0045   # Approximate degrees for 500m in latitude\n",
    "delta_lon = 0.0060   # Approximate degrees for 500m in longitude\n",
    "\n",
    "# This is your foreachBatch function to process each micro-batch\n",
    "def process_batch(batch_df, batch_id):\n",
    "    # Skip empty batches\n",
    "    if batch_df.rdd.isEmpty():\n",
    "        return\n",
    "\n",
    "    # PART A: Compute the 30-minute window based on the batch’s max dropoff\n",
    "    max_dropoff = batch_df.agg({\"dropoff_datetime\": \"max\"}).collect()[0][0]\n",
    "    if max_dropoff is None:\n",
    "        return\n",
    "    ref_time = max_dropoff - timedelta(minutes=30)\n",
    "\n",
    "    # PART B: Compute grid cell IDs for pickup and dropoff using the 500m grid\n",
    "    batch_df = batch_df.withColumn(\n",
    "        \"pickup_cell_east\", floor((col(\"pickup_longitude\") - lit(grid_origin_lon)) / lit(delta_lon)) + 1\n",
    "    ).withColumn(\n",
    "        \"pickup_cell_south\", floor((lit(grid_origin_lat) - col(\"pickup_latitude\")) / lit(delta_lat)) + 1\n",
    "    ).withColumn(\n",
    "        \"start_cell\", concat(col(\"pickup_cell_east\").cast(\"int\"), lit(\".\"), col(\"pickup_cell_south\").cast(\"int\"))\n",
    "    )\n",
    "    batch_df = batch_df.withColumn(\n",
    "        \"dropoff_cell_east\", floor((col(\"dropoff_longitude\") - lit(grid_origin_lon)) / lit(delta_lon)) + 1\n",
    "    ).withColumn(\n",
    "        \"dropoff_cell_south\", floor((lit(grid_origin_lat) - col(\"dropoff_latitude\")) / lit(delta_lat)) + 1\n",
    "    ).withColumn(\n",
    "        \"end_cell\", concat(col(\"dropoff_cell_east\").cast(\"int\"), lit(\".\"), col(\"dropoff_cell_south\").cast(\"int\"))\n",
    "    )\n",
    "\n",
    "    # Filter out trips that are out-of-bounds (only consider cells 1 to 300)\n",
    "    batch_df = batch_df.filter(\n",
    "        (col(\"pickup_cell_east\").between(1, 300)) &\n",
    "        (col(\"pickup_cell_south\").between(1, 300)) &\n",
    "        (col(\"dropoff_cell_east\").between(1, 300)) &\n",
    "        (col(\"dropoff_cell_south\").between(1, 300))\n",
    "    )\n",
    "\n",
    "    # PART C: Filter for trips with dropoff_datetime >= ref_time (last 30 minutes)\n",
    "    df_last30 = batch_df.filter(col(\"dropoff_datetime\") >= F.lit(ref_time))\n",
    "    print(f\"Window filter: dropoff_datetime >= {ref_time}\")\n",
    "    print(\"df_last30 count =\", df_last30.count())\n",
    "    df_last30.show(5)\n",
    "\n",
    "\n",
    "    # PART D: Aggregate routes and get top 10 most frequent\n",
    "    df_frequent_routes = df_last30.groupBy(\"start_cell\", \"end_cell\") \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\", \"Number_of_Rides\")\n",
    "    top10_routes = df_frequent_routes.orderBy(col(\"Number_of_Rides\").desc()).limit(10)\n",
    "    top10_list = top10_routes.collect()\n",
    "\n",
    "    # PART E: Determine a triggering event and compute delay\n",
    "    # Choose the event with the maximum dropoff_datetime as the trigger\n",
    "    trigger_row = batch_df.orderBy(col(\"dropoff_datetime\").desc()).limit(1).collect()[0]\n",
    "    trigger_pickup = trigger_row[\"pickup_datetime\"]\n",
    "    trigger_dropoff = trigger_row[\"dropoff_datetime\"]\n",
    "    ingest_time = trigger_row[\"ingest_time\"]\n",
    "    processing_time = datetime.now()\n",
    "    delay = (processing_time - ingest_time).total_seconds()\n",
    "\n",
    "    # PART F: Build the output row\n",
    "    output_row = {\n",
    "        \"pickup_datetime\": trigger_pickup,\n",
    "        \"dropoff_datetime\": trigger_dropoff,\n",
    "        \"delay\": delay\n",
    "    }\n",
    "    for i in range(10):\n",
    "        if i < len(top10_list):\n",
    "            route = top10_list[i]\n",
    "            output_row[f\"start_cell_id_{i+1}\"] = route[\"start_cell\"]\n",
    "            output_row[f\"end_cell_id_{i+1}\"] = route[\"end_cell\"]\n",
    "        else:\n",
    "            output_row[f\"start_cell_id_{i+1}\"] = None\n",
    "            output_row[f\"end_cell_id_{i+1}\"] = None\n",
    "\n",
    "    # For demonstration, print the output update\n",
    "    print(f\"Update for batch {batch_id} :\", output_row)\n",
    "    \n",
    "    # Define the output schema explicitly\n",
    "    output_schema = StructType([\n",
    "        StructField(\"pickup_datetime\", TimestampType(), True),\n",
    "        StructField(\"dropoff_datetime\", TimestampType(), True),\n",
    "        StructField(\"start_cell_id_1\", StringType(), True),\n",
    "        StructField(\"end_cell_id_1\", StringType(), True),\n",
    "        StructField(\"start_cell_id_2\", StringType(), True),\n",
    "        StructField(\"end_cell_id_2\", StringType(), True),\n",
    "        StructField(\"start_cell_id_3\", StringType(), True),\n",
    "        StructField(\"end_cell_id_3\", StringType(), True),\n",
    "        StructField(\"start_cell_id_4\", StringType(), True),\n",
    "        StructField(\"end_cell_id_4\", StringType(), True),\n",
    "        StructField(\"start_cell_id_5\", StringType(), True),\n",
    "        StructField(\"end_cell_id_5\", StringType(), True),\n",
    "        StructField(\"start_cell_id_6\", StringType(), True),\n",
    "        StructField(\"end_cell_id_6\", StringType(), True),\n",
    "        StructField(\"start_cell_id_7\", StringType(), True),\n",
    "        StructField(\"end_cell_id_7\", StringType(), True),\n",
    "        StructField(\"start_cell_id_8\", StringType(), True),\n",
    "        StructField(\"end_cell_id_8\", StringType(), True),\n",
    "        StructField(\"start_cell_id_9\", StringType(), True),\n",
    "        StructField(\"end_cell_id_9\", StringType(), True),\n",
    "        StructField(\"start_cell_id_10\", StringType(), True),\n",
    "        StructField(\"end_cell_id_10\", StringType(), True),\n",
    "        StructField(\"delay\", DoubleType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Create the DataFrame using the explicit schema\n",
    "    result_df = spark.createDataFrame([output_row], schema=output_schema)\n",
    "    result_df.show(truncate=False)\n",
    "\n",
    "# If your taxi data doesn’t already have proper types, ensure you convert the datetime columns\n",
    "streaming_df = streaming_df.withColumn(\"pickup_datetime\", to_timestamp(col(\"pickup_datetime\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "streaming_df = streaming_df.withColumn(\"dropoff_datetime\", to_timestamp(col(\"dropoff_datetime\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "streaming_df = streaming_df.withColumn(\"ingest_time\", current_timestamp())\n",
    "\n",
    "# Use trigger(once=True) to process existing data exactly one time\n",
    "query = (\n",
    "    streaming_df.writeStream\n",
    "    .trigger(once=True)                # <--- This forces the query to run just once\n",
    "    .foreachBatch(process_batch)\n",
    "    .outputMode(\"append\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4942a784-1036-49ee-baca-d583019bfd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
